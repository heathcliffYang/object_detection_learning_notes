# Object detection learning materials

æŠŠè’é›†åˆ°çš„ä¸éŒ¯çš„æ–‡ç« ã€å€¼å¾—æ·±ç©¶çš„åè©(æˆ–æ±è¥¿)è¨˜éŒ„ä¸‹ä¾†ï¼Œä¸¦æ›´æ·±åº¦å­¸ç¿’ï¼

[é€™å€‹ç¶²ç«™](https://paperswithcode.com/sota/object-detection-on-coco)å¯ä»¥çŸ¥é“ dataset ä¸‹å„å®¶ model çš„è¡¨ç¾å¦‚ä½•ï¼Ÿ

## Measure

:apple: [Object detection metrics](https://github.com/rafaelpadilla/Object-Detection-Metrics) è§£é‡‹äº†å¾ˆå¤šé‡æ¸¬çš„æ–¹æ³•

### IOU

IoU (intersection over union) is a way to determine whether the object proposal is right or not. A is proposed region and B is ground-truth region :
$$
IoU(A,B) = \frac{A \cap B}{A \cup B}
$$
By applying the IOU we can tell if a detection is valid (True Positive) or not (False Positive).

### TP, FP, FN and TN

- TP : a proposal was made for class ğ‘ and there actually was an object of class ğ‘. :apple: graph
- FP :  a proposal was made for class ğ‘ but there is no object of class ğ‘. :apple: graph
- FN: A ground truth not detected

### Precision

ability of a model to identify only the relevant objects.
$$
Precision = \frac{TP}{TP+FP}
$$

### Recall

ability of a model to find all the relevant cases (all ground truth bounding boxes). (sensity)
$$
Recall = \frac{TP}{TP+FN}
$$

### Average precision

calculate the area under the curve (AUC) of the Precision x Recall curve.

### interpolating all points

$$
\sum_{n=0}(r_{n+1}-r_n)\rho_{interp}(r_{n+1})
$$

where $\rho_{interp}(r_{n+1})$ is the measured precision at recall $r$.

:apple: maximum precision whose recall value is greater or equal than $r+1$

### Precision x Recall curve

To plot precision x recall curve, we sort all detections by descending confidence, record accumulative TP and FP, and then we can calculate precision and record. [example](https://github.com/rafaelpadilla/Object-Detection-Metrics#different-competitions-different-metrics)






![](https://i.imgur.com/3iAJybu.png)


## YOLOv4
å‹å–„çš„[ä¸­æ–‡ä»‹ç´¹](https://zhuanlan.zhihu.com/p/135909702)å¯ä»¥å…ˆçœ‹ä¸€ä¸‹ã€‚ä»¥ä¸‹æ˜¯ yolov4 ä¸»è¦çµ„æˆè·Ÿè©²éšæ®µçš„ improving skillsï¼š
- Backbone: CSPDarknet53 - ä¸»è¦ç›®çš„æ˜¯
    - BoF
        -  data augmentation: CutMix(2019), Mosaic
            ![](https://i.imgur.com/V9BS4ga.png)
            CutMix å¯ä»¥å¾—åˆ°æ¯” Mixup & Cutout æ›´å¥½çš„çµæœï¼Œä½† bounding box ground truth è¦é‡åš
            ![](https://i.imgur.com/hOQaMKW.png)
            æ ¹æ“šä¸‹åœ–å¯ä»¥çœ‹å‡º Mosaic æ˜¯ BoF è£¡æœ€å…·å½±éŸ¿åŠ›çš„æ–¹æ³•ï¼Œä½† bbox ä¸€æ¨£è¦è§£æ±º
            ![](https://i.imgur.com/cwHP0aR.png)
        - regularization: DropBlock, æŠŠé®æ“‹çš„æ¦‚å¿µé‹ç”¨åœ¨ model ä¸­
        - Class labeling smoothing: ä¸è¦çµ•å°çš„ 1 è·Ÿ 0 ï¼Œç›®æ¨™æ˜¯è§£æ±º overfitting & **overconfidence**
    - BoS
        - Mish activation
        - Cross-stage partial connections (CSP)
        - Multi-input weighted residual connections (MiWRC)
- Neckï¼šSPP, PAN - ä¸»è¦ç›®çš„æ˜¯
- Headï¼šYOLOv3 - ä¸»è¦ç›®çš„æ˜¯

For detectorï¼š
- BoF
	- [ ] data augmentation: Mosaic
    - [ ] regularization: DropBlock
    - [ ] Self-Adversarial Training
    - [ ] Eliminate grid sensitivity
    - [ ] Using multiple anchors for a single ground truth
    - [ ] Cosine annealing scheduler
    - [ ] Optimal hyper- parameters
    - [ ] Random training shapes
    - [ ] CmBN
    - [ ] CIoU-loss
- BoS
    - [ ] Mish activation
    - [ ] SPP-block
    - [ ] SAM-block
    - [ ] PAN path-aggregation block
    - [ ] DIoU-NMS

æ–‡å…§é‚„æ•´ç†äº†çœ¾å¤šæ¨¡å‹çš„ä¸åŒåŠŸèƒ½ã€éš¸å±¬çš„éšæ®µ (è«–æ–‡ fig.2)

æ¨¡å‹èˆ‡å…¶é‹ç”¨çš„ç¡¬é«”ä¹Ÿæœ‰é—œä¿‚ï¼š
- GPU: CSPResNeXt50 / CSPDarknet53 (CPSNet ä¹Ÿè©²çœ‹ä¸€ä¸‹ï¼)
- VPU: EfficientNet-lite / MixNet / GhostNet / MobileNetV3 (What is VPU?)

### tiny-yolo æ˜¯ä»€éº¼ï¼Ÿ
[ä¸­æ–‡ç¶²ç«™](https://zhuanlan.zhihu.com/p/151389749)

![](https://i.imgur.com/gZiOdZ4.png)


## YOLOv5
[é€™ç¯‡æ–‡ç« ](https://zhuanlan.zhihu.com/p/161083602)æœ‰é‡å° v5 è·Ÿ v4 çš„å·®åˆ¥åšæ¯”è¼ƒ



## References
å¯ä»¥çœ‹ [è¨ˆç®—æ©Ÿè¦–è¦ºè«–æ–‡é€Ÿé](https://zhuanlan.zhihu.com/c_172507674) è·Ÿä¸Šä¸€ä¸‹æ–°çŸ¥
